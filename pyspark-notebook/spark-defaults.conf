# Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements.  See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the "License"); you may not use this file except in compliance with
# the License.  You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#

# K8s Jupyter Notebook client mode settings
# spark.kubernetes.namespace                                                                jhubspark-jhub
# spark.kubernetes.node.selector.agentpool                                                  sparkpool
# spark.kubernetes.container.image                                                          jhubspark.azurecr.io/spark-worker:v3.2.1
# spark.kubernetes.container.image.pullSecrets                                              jhubsparkacr-secret
# spark.kubernetes.authenticate.driver.serviceAccountName                                   spark-admin
# spark.hadoop.fs.azure.account.auth.type.pitcrewstorage.dfs.core.windows.net               SharedKey
# spark.hadoop.fs.azure.account.key.pitcrewstorage.dfs.core.windows.net                     hB8d+muYJy4yUey6P4fWLEhi/iexF20seH2AIWGbw0jNq89amrbyAfYegTuTWWlXKVVGEqWpFysQJfpuOHsJbA==
# spark.hadoop.fs.azure.account.auth.type.pitcrewstorage.blob.core.windows.net              SharedKey
# spark.hadoop.fs.azure.account.key.pitcrewstorage.blob.core.windows.net                    hB8d+muYJy4yUey6P4fWLEhi/iexF20seH2AIWGbw0jNq89amrbyAfYegTuTWWlXKVVGEqWpFysQJfpuOHsJbA==
# spark.kubernetes.executor.volumes.persistentVolumeClaim.user-claim.options.claimName      pvc-test-jhub-user
# spark.kubernetes.executor.volumes.persistentVolumeClaim.project-claim.options.claimName   pvc-test-jhub-project
spark.master                                                                                k8s://https://kubernetes.default:443
spark.kubernetes.authenticate.caCertFile                                                    /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
spark.kubernetes.authenticate.oauthTokenFile                                                /var/run/secrets/kubernetes.io/serviceaccount/token
spark.kubernetes.pyspark.pythonversion                                                      3
spark.scheduler.maxRegisteredResourcesWaitingTime                                           3600s
spark.scheduler.minRegisteredResourcesRatio                                                 1
spark.kubernetes.allocation.batch.size                                                      100
spark.sql.legacy.timeParserPolicy                                                           LEGACY
spark.sql.extensions                                                                        io.delta.sql.DeltaSparkSessionExtension
spark.sql.catalog.spark_catalog                                                             org.apache.spark.sql.delta.catalog.DeltaCatalog
spark.kubernetes.executor.volumes.persistentVolumeClaim.user-claim.mount.path               /home/jovyan/work
spark.kubernetes.executor.volumes.persistentVolumeClaim.project-claim.mount.path            /home/jovyan/shared
spark.kubernetes.executor.volumes.persistentVolumeClaim.lakehouse-claim.mount.path          /home/jovyan/lakehouse
spark.sql.hive.metastore.version                                                            2.3.9
spark.sql.hive.metastore.jars                                                               maven
# spark.hadoop.javax.jdo.option.ConnectionURL                                                 jdbc:mysql://zus1fssametastore.mysql.database.azure.com:3306/hive_metastore
# spark.hadoop.javax.jdo.option.ConnectionDriverName                                          org.mariadb.jdbc.Driver
# spark.hadoop.javax.jdo.option.ConnectionDriverName                                          com.microsoft.sqlserver.jdbc.SQLServerDriver
# spark.hadoop.javax.jdo.option.ConnectionUserName                                            hive_admin@zus1fssametastore
# spark.hadoop.javax.jdo.option.ConnectionPassword                                            A5hR4$vCw8c%$qp$gn3k
# spark.hadoop.datanucleus.autoCreateSchema                                                   true
# spark.hadoop.datanucleus.fixedDatastore                                                     false
# spark.sql.hive.metastore.schema.verification                                                false
# spark.sql.hive.metastore.schema.verification.record.version                                 false
